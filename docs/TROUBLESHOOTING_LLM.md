# Guide de d√©pannage LLM - EBIOS RM

## üö® Probl√®mes courants et solutions

### 1. **Erreur Qwen 403 (Acc√®s refus√©)**

#### Sympt√¥mes
```
Erreur Qwen: 403
Failed to load resource: the server responded with a status of 403
```

#### Causes possibles
- **Cl√© API invalide ou manquante**
- **Cl√© API sans acc√®s au mod√®le demand√©**
- **Quota d√©pass√©**
- **R√©gion non support√©e**

#### Solutions
1. **V√©rifier la cl√© API**
   - Aller dans **Param√®tres** ‚Üí **Qwen**
   - S'assurer que la cl√© API est correctement saisie
   - Obtenir une nouvelle cl√© sur [Alibaba Cloud DashScope](https://dashscope.console.aliyun.com/)

2. **Changer de mod√®le**
   - Essayer `qwen-max` au lieu de `qwen3-max`
   - Utiliser `qwen2.5-72b-instruct` comme alternative

3. **V√©rifier les quotas**
   - Consulter votre tableau de bord Alibaba Cloud
   - V√©rifier les limites de votre compte

### 2. **Erreur OpenAI CORS**

#### Sympt√¥mes
```
Access to fetch at 'https://api.openai.com/compatible-mode/v1/chat/completions' 
from origin 'http://localhost:5176' has been blocked by CORS policy
```

#### Cause
- **URL incorrecte** : L'URL contient `/compatible-mode/` qui est sp√©cifique √† Qwen

#### Solution
1. **Vider le cache du navigateur**
   - Ctrl+Shift+R (Windows/Linux) ou Cmd+Shift+R (Mac)
   - Ou aller dans les outils d√©veloppeur ‚Üí Application ‚Üí Storage ‚Üí Clear storage

2. **Red√©marrer l'application**
   ```bash
   # Arr√™ter le serveur de d√©veloppement
   Ctrl+C
   
   # Relancer
   npm run dev
   ```

3. **V√©rifier la configuration OpenAI**
   - Aller dans **Param√®tres** ‚Üí **OpenAI**
   - S'assurer que l'URL de base est `https://api.openai.com` (ou vide)

### 3. **Probl√®mes d'authentification g√©n√©raux**

#### Erreur 401 (Non autoris√©)
- **Cl√© API invalide** : V√©rifier et r√©g√©n√©rer la cl√©
- **Format incorrect** : S'assurer qu'il n'y a pas d'espaces avant/apr√®s

#### Erreur 429 (Trop de requ√™tes)
- **Quota d√©pass√©** : Attendre ou upgrader le plan
- **Rate limiting** : R√©duire la fr√©quence des appels

### 4. **Probl√®mes de connectivit√©**

#### Services locaux (Ollama, LM Studio)
```
Failed to fetch
TypeError: Failed to fetch
```

**Solutions :**
1. **V√©rifier que le service est d√©marr√©**
   ```bash
   # Pour Ollama
   ollama serve
   
   # Pour LM Studio
   # D√©marrer LM Studio et activer le serveur local
   ```

2. **V√©rifier l'URL**
   - Ollama : `http://localhost:11434`
   - LM Studio : `http://localhost:1234`

3. **Tester la connectivit√©**
   ```bash
   # Test Ollama
   curl http://localhost:11434/api/tags
   
   # Test LM Studio
   curl http://localhost:1234/v1/models
   ```

### 5. **Probl√®mes de mod√®les**

#### Mod√®le non trouv√©
- **V√©rifier la disponibilit√©** du mod√®le sur la plateforme
- **Utiliser un mod√®le alternatif** de la liste

#### Mod√®les recommand√©s par fournisseur
- **Gemini** : `gemini-2.5-pro-latest`
- **OpenAI** : `gpt-5` ou `gpt-4o`
- **Anthropic** : `claude-sonnet-4-20250514`
- **Qwen** : `qwen-max` (plus stable que `qwen3-max`)

## üîß Outils de diagnostic

### 1. **Testeur LLM int√©gr√©**
1. Aller dans **Param√®tres**
2. Cliquer sur **üß™ Tester tous les LLM**
3. Voir les r√©sultats d√©taill√©s pour chaque fournisseur

### 2. **Console du navigateur**
1. Ouvrir les outils d√©veloppeur (F12)
2. Aller dans l'onglet **Console**
3. Chercher les logs d√©taill√©s :
   ```
   [LLM] Initialisation du service pour le fournisseur: qwen
   [Qwen] Appel API vers: https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
   [Qwen] Mod√®le utilis√©: qwen-max
   [Qwen] Cl√© API configur√©e: Oui
   ```

### 3. **Onglet Network**
1. Ouvrir les outils d√©veloppeur (F12)
2. Aller dans l'onglet **Network**
3. Reproduire l'erreur
4. Examiner les requ√™tes HTTP pour voir les d√©tails

## üìã Checklist de d√©pannage

### Avant de commencer
- [ ] V√©rifier la connexion internet
- [ ] S'assurer que les cl√©s API sont valides
- [ ] V√©rifier les quotas des services cloud

### Pour chaque fournisseur
- [ ] Cl√© API correctement configur√©e
- [ ] Mod√®le disponible et accessible
- [ ] URL de base correcte
- [ ] Pas de caract√®res sp√©ciaux dans la configuration

### Tests de validation
- [ ] Test de connectivit√© individuel
- [ ] Test de g√©n√©ration JSON
- [ ] V√©rification des logs de la console
- [ ] Test avec un mod√®le alternatif

## üÜò Solutions d'urgence

### Si aucun LLM ne fonctionne
1. **Utiliser Gemini** (g√©n√©ralement le plus stable)
2. **V√©rifier la configuration par d√©faut**
3. **R√©initialiser les param√®tres** (bouton R√©initialiser)
4. **Red√©marrer l'application**

### Si seul Gemini fonctionne
1. **C'est normal** - Gemini est le plus stable
2. **Configurer les autres progressivement**
3. **Utiliser le testeur pour valider**

### Configuration minimale fonctionnelle
```json
{
  "provider": "gemini",
  "gemini": {
    "apiKey": "VOTRE_CLE_GEMINI",
    "model": "gemini-2.5-pro-latest",
    "baseUrl": "https://generativelanguage.googleapis.com"
  }
}
```

## üìû Support suppl√©mentaire

### Logs utiles √† fournir
1. **Messages d'erreur complets** de la console
2. **Configuration utilis√©e** (sans les cl√©s API)
3. **√âtapes pour reproduire** le probl√®me
4. **R√©sultats du testeur LLM**

### Ressources externes
- [Documentation Gemini](https://ai.google.dev/docs)
- [Documentation OpenAI](https://platform.openai.com/docs)
- [Documentation Anthropic](https://docs.anthropic.com/)
- [Documentation Qwen/DashScope](https://help.aliyun.com/zh/model-studio/)

### Communaut√©
- V√©rifier les status des services sur leurs pages officielles
- Consulter les forums de d√©veloppeurs
- V√©rifier les mises √† jour des mod√®les

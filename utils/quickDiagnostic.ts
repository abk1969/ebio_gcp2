/**
 * Diagnostic rapide pour identifier le probl√®me OpenAI
 */

import configService from '../services/configService';

export const quickOpenAIDiagnostic = async (): Promise<void> => {
  console.log('üîç === DIAGNOSTIC RAPIDE OPENAI ===');
  
  try {
    // 1. V√©rifier la configuration
    const config = configService.getConfig();
    const openaiConfig = config.openai;
    
    console.log('üìã Configuration OpenAI:');
    console.log('- Cl√© API configur√©e:', openaiConfig?.apiKey ? 'Oui' : 'Non');
    console.log('- Format cl√© API:', openaiConfig?.apiKey ? (openaiConfig.apiKey.startsWith('sk-') ? 'Correct' : 'Incorrect') : 'N/A');
    console.log('- Mod√®le:', openaiConfig?.model || 'Non d√©fini');
    console.log('- URL de base:', openaiConfig?.baseUrl || 'Non d√©finie');
    
    if (!openaiConfig?.apiKey) {
      console.error('‚ùå PROBL√àME: Cl√© API OpenAI manquante');
      console.log('üí° SOLUTION: Configurer la cl√© API dans Param√®tres ‚Üí OpenAI');
      return;
    }
    
    if (!openaiConfig.apiKey.startsWith('sk-')) {
      console.error('‚ùå PROBL√àME: Format de cl√© API incorrect');
      console.log('üí° SOLUTION: La cl√© doit commencer par "sk-"');
      return;
    }
    
    // 2. Test de connectivit√© simple
    console.log('\nüåê Test de connectivit√©...');
    const response = await fetch('https://api.openai.com/v1/models', {
      method: 'GET',
      headers: {
        'Authorization': `Bearer ${openaiConfig.apiKey}`
      }
    });
    
    console.log('- Statut HTTP:', response.status);
    
    if (response.status === 401) {
      console.error('‚ùå PROBL√àME: Cl√© API invalide (401)');
      console.log('üí° SOLUTION: V√©rifier/r√©g√©n√©rer la cl√© API sur platform.openai.com');
      return;
    }
    
    if (response.status === 403) {
      console.error('‚ùå PROBL√àME: Acc√®s refus√© (403)');
      console.log('üí° SOLUTION: V√©rifier les permissions de la cl√© API');
      return;
    }
    
    if (response.status === 429) {
      console.error('‚ùå PROBL√àME: Quota d√©pass√© (429)');
      console.log('üí° SOLUTION: Attendre ou upgrader le plan OpenAI');
      return;
    }
    
    if (!response.ok) {
      console.error('‚ùå PROBL√àME: Erreur HTTP', response.status);
      return;
    }
    
    const data = await response.json();
    console.log('‚úÖ Connectivit√© OK -', data.data?.length || 0, 'mod√®les disponibles');
    
    // 3. V√©rifier l'acc√®s au mod√®le
    const modelId = openaiConfig.model;
    const availableModels = data.data?.map((m: any) => m.id) || [];
    
    if (availableModels.includes(modelId)) {
      console.log('‚úÖ Mod√®le accessible:', modelId);
      
      // Avertissement sp√©cial pour GPT-5
      if (modelId.includes('gpt-5')) {
        console.warn('‚ö†Ô∏è ATTENTION: GPT-5 est tr√®s instable et peut renvoyer des r√©ponses vides');
        console.log('üí° RECOMMANDATION FORTE: Changer vers gpt-4o pour une exp√©rience stable');
        console.log('üîß Pour changer: Param√®tres ‚Üí OpenAI ‚Üí Mod√®le ‚Üí gpt-4o');
      }
    } else {
      console.error('‚ùå PROBL√àME: Mod√®le non accessible:', modelId);
      console.log('üí° SOLUTION: Utiliser un mod√®le accessible comme gpt-4o-mini ou gpt-3.5-turbo');
      console.log('üìã Mod√®les disponibles:', availableModels.slice(0, 5).join(', '), '...');
      return;
    }
    
    // 4. Test de g√©n√©ration simple
    console.log('\nüí¨ Test de g√©n√©ration...');

    // Pr√©parer les param√®tres selon le mod√®le
    const requestBody: any = {
      model: modelId,
      messages: [{ role: 'user', content: 'Hello' }], // Prompt plus simple pour GPT-5
      temperature: 0.7
    };

    // Ajuster les param√®tres selon le mod√®le
    if (modelId.includes('gpt-5')) {
      // Param√®tres officiels GPT-5 - version minimale pour test
      requestBody.temperature = 1; // Obligatoire
      requestBody.max_completion_tokens = 10; // Tr√®s petit pour test
      
      console.log('üîß Configuration GPT-5 appliqu√©e:', {
        model: modelId,
        temperature: requestBody.temperature,
        max_completion_tokens: requestBody.max_completion_tokens,
        message: requestBody.messages[0].content
      });
    } else if (modelId.includes('o1-')) {
      requestBody.temperature = 1;
      requestBody.max_completion_tokens = 50;
    } else {
      requestBody.max_tokens = 50;
    }

    console.log('üìã Param√®tres de test:', JSON.stringify(requestBody, null, 2));

    const testResponse = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${openaiConfig.apiKey}`
      },
      body: JSON.stringify(requestBody)
    });
    
    if (!testResponse.ok) {
      const errorData = await testResponse.json().catch(() => ({}));
      console.error('‚ùå PROBL√àME: Erreur de g√©n√©ration:', testResponse.status);
      console.error('D√©tails complets:', errorData);

      // Analyser les erreurs 400 sp√©cifiques
      if (testResponse.status === 400) {
        const errorMessage = errorData.error?.message || '';
        console.log('üìã Message d\'erreur:', errorMessage);

        if (errorMessage.includes('max_tokens')) {
          console.log('üí° SOLUTION: Probl√®me avec max_tokens - utiliser max_completion_tokens pour ce mod√®le');
        } else if (errorMessage.includes('temperature')) {
          console.log('üí° SOLUTION: Probl√®me avec temperature - utiliser temperature: 1 pour ce mod√®le');
        } else if (errorMessage.includes('response_format')) {
          console.log('üí° SOLUTION: Probl√®me avec response_format - ce mod√®le ne le supporte pas');
        } else if (errorMessage.includes('model')) {
          console.log('üí° SOLUTION: Probl√®me avec le mod√®le - essayer gpt-4o-mini ou gpt-3.5-turbo');
        } else {
          console.log('üí° SOLUTION: Erreur 400 g√©n√©rique - v√©rifier les param√®tres de la requ√™te');
        }
      }
      return;
    }
    
    const testData = await testResponse.json();
    const content = testData.choices?.[0]?.message?.content;
    
    if (content && content.trim()) {
      console.log('‚úÖ G√©n√©ration OK:', content.trim());
      console.log('üéâ OpenAI fonctionne correctement !');
    } else {
      console.error('‚ùå PROBL√àME: R√©ponse vide de OpenAI');
      console.error('R√©ponse compl√®te:', testData);

      // Analyser la structure de la r√©ponse
      console.log('üîç ANALYSE D√âTAILL√âE DE LA R√âPONSE:');
      console.log('üìã R√©ponse compl√®te:', JSON.stringify(testData, null, 2));

      // Extraire automatiquement les choices
      if (testData.choices && testData.choices.length > 0) {
        testData.choices.forEach((choice: any, index: number) => {
          console.log(`üìã Choice ${index}:`, JSON.stringify(choice, null, 2));
          console.log(`üìã Choice ${index} - finish_reason:`, choice.finish_reason);
          console.log(`üìã Choice ${index} - message:`, JSON.stringify(choice.message, null, 2));

          if (choice.message) {
            console.log(`üìã Choice ${index} - content type:`, typeof choice.message.content);
            console.log(`üìã Choice ${index} - content value:`, choice.message.content);
            console.log(`üìã Choice ${index} - content length:`, choice.message.content?.length || 0);
            console.log(`üìã Choice ${index} - content is null:`, choice.message.content === null);
            console.log(`üìã Choice ${index} - content is undefined:`, choice.message.content === undefined);
            console.log(`üìã Choice ${index} - content is empty string:`, choice.message.content === '');
          }
        });
      } else {
        console.log('‚ùå Aucun choices dans la r√©ponse');
      }

      // Analyser les raisons d'arr√™t
      const firstChoice = testData.choices?.[0];
      if (firstChoice) {
        if (firstChoice.finish_reason === 'length') {
          console.log('üí° SOLUTION: Limite de tokens atteinte - augmenter max_tokens/max_completion_tokens');
        } else if (firstChoice.finish_reason === 'content_filter') {
          console.log('üí° SOLUTION: Contenu filtr√© - modifier le prompt');
        } else if (firstChoice.message?.content === null) {
          console.log('üí° SOLUTION: Contenu null - probl√®me avec les param√®tres du mod√®le GPT-5');
          console.log('üí° RECOMMANDATION: Essayer avec gpt-4o au lieu de gpt-5');
        } else {
          console.log('üí° SOLUTION: V√©rifier les param√®tres du mod√®le');
        }
      }
    }
    
  } catch (error) {
    console.error('‚ùå PROBL√àME: Erreur de connexion:', error);
    console.log('üí° SOLUTION: V√©rifier la connexion internet');
  }
  
  console.log('\nüîç === FIN DU DIAGNOSTIC ===');
};

/**
 * Affiche les mod√®les OpenAI disponibles
 */
export const showOpenAIModels = (): void => {
  console.log('üìã Mod√®les OpenAI disponibles:');
  console.log('  - gpt-4o (Performance √©lev√©e)');
  console.log('  - gpt-4o-mini (Plus accessible)');
  console.log('  - gpt-3.5-turbo (Le plus accessible)');
  console.log('  - gpt-4-turbo (Version turbo)');
  console.log('  - gpt-5 (Derni√®re version)');
  console.log('  - gpt-o3 (Nouvelle g√©n√©ration)');
  console.log('üí° Changez le mod√®le via l\'interface utilisateur dans les Param√®tres');
};

/**
 * Nettoie les mod√®les obsol√®tes dans la configuration
 */
export const cleanObsoleteModels = (): void => {
  console.log('üßπ Nettoyage des mod√®les obsol√®tes...');

  const config = configService.getConfig();
  let updated = false;

  // Nettoyer les mod√®les Gemini avec -latest
  if (config.gemini.model.includes('-latest')) {
    console.log(`  - Gemini: ${config.gemini.model} ‚Üí ${config.gemini.model.replace('-latest', '')}`);
    config.gemini.model = config.gemini.model.replace('-latest', '');
    updated = true;
  }

  // Nettoyer les mod√®les Mistral avec -latest (optionnel, car ils supportent encore -latest)
  // if (config.mistral.model.includes('-latest')) {
  //   console.log(`  - Mistral: ${config.mistral.model} ‚Üí ${config.mistral.model.replace('-latest', '')}`);
  //   config.mistral.model = config.mistral.model.replace('-latest', '');
  //   updated = true;
  // }

  if (updated) {
    configService.updateConfig(config);
    console.log('‚úÖ Configuration mise √† jour');
  } else {
    console.log('‚úÖ Aucun mod√®le obsol√®te trouv√©');
  }
};

// Fonctions disponibles dans la console
(window as any).quickOpenAIDiagnostic = quickOpenAIDiagnostic;
(window as any).showOpenAIModels = showOpenAIModels;
(window as any).cleanObsoleteModels = cleanObsoleteModels;
